stages:
  parse_audits:
    cmd: python3 scripts/get_reports.py
    outs: 
    - data/audits_info.json # [{audit_link, report_link, None, None}]
  parse_git_links:
    cmd: python3 scripts/get_repositories.py
    deps: 
    - data/audits_info.json
    outs: 
    - data/audits_info.json # [{audit_link, report_link, git_link, None}]
  clone_repositories:
    cmd: python3 scripts/download_repositories.py
    deps: 
    - data/audits_info.json
    outs: 
    - data/repositories
    - data/audits_info.json # [{audit_link, report_link, git_link, local_path}]
  # preprocess:
  #   cmd: python3 scripts/preprocess_repositories.py
  #   deps:
  #   - data/repositories
  #   outs: 
  #   - data/processed_repositories # remove folders, ast via slither
  slither_analyze:
    cmd: python3 scripts/slither_main.py
    deps:
    - data/repositories
    outs:
    - data/processed_repositories # json {function_name, code, relationships}
  parse_issues:
    cmd: python3 scripts/parse_issues.py
    deps:
    - data/audits_info.json
    outs:
    - data/reports

# Application: RAG with finetune codebert + GNN relationship enriched embeddings
# Finetune: Lora Codebert on DISL dataset -> path/to/model
# GNN enrichment: GNN(finetune_embeddings(processed_repositories)) on link prediction + contrastive learning
# + ???
# RAG: langchain_rag+faiss_pipeline+fastapiapp+GNN+processed_repositories->test rag 