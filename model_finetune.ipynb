{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"V28"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9062970c8e7b48cabaf29e0b158848c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7cc3f42ec30f4116a7c87ca563373b38","IPY_MODEL_320ef60e7c4d48da903db5949d44939e","IPY_MODEL_e725951ac26d4de3996cace41fc82090"],"layout":"IPY_MODEL_d335bb6f90dc415e872cfadf06b505cc"}},"7cc3f42ec30f4116a7c87ca563373b38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2b19aa14ef847e49167b775cd1dc0b9","placeholder":"​","style":"IPY_MODEL_ddc251aa852b42fe86d3acba0779e746","value":"tokenizer_config.json: 100%"}},"320ef60e7c4d48da903db5949d44939e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_688bda0b9635459099fa4396bf68c50f","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8848928c425c43aeb7319501e9b65b3a","value":25}},"e725951ac26d4de3996cace41fc82090":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49a8f66e4fc646ee84683656cf39a236","placeholder":"​","style":"IPY_MODEL_04eb1425b6494762841c14fbe4345682","value":" 25.0/25.0 [00:00&lt;00:00, 634B/s]"}},"d335bb6f90dc415e872cfadf06b505cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2b19aa14ef847e49167b775cd1dc0b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddc251aa852b42fe86d3acba0779e746":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"688bda0b9635459099fa4396bf68c50f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8848928c425c43aeb7319501e9b65b3a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49a8f66e4fc646ee84683656cf39a236":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04eb1425b6494762841c14fbe4345682":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0dcd7a0c2ce46a19833029b9cd68bf5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_310de2b8921a477b992f1f3ef8455eb1","IPY_MODEL_e8c492d6806e4862b02f00ad8b0af61c","IPY_MODEL_318da11eabf24278bcda696246972b0a"],"layout":"IPY_MODEL_68ace88f8cb544e79f19d7582a7f55f5"}},"310de2b8921a477b992f1f3ef8455eb1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_773edb7711364b93a2d1484a3cc98026","placeholder":"​","style":"IPY_MODEL_a00f52831f2a4c158bdebf6f6ff88675","value":"vocab.json: 100%"}},"e8c492d6806e4862b02f00ad8b0af61c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dc64b93431346c6a5a6da75129ee0fe","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37e1af5a7afb47d3af8f7a7104a70fce","value":898822}},"318da11eabf24278bcda696246972b0a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7037ae459fe940a7b163718be878daa4","placeholder":"​","style":"IPY_MODEL_4fcbde0c8c1644a7bb4fb9b5fe4b9a15","value":" 899k/899k [00:00&lt;00:00, 1.02MB/s]"}},"68ace88f8cb544e79f19d7582a7f55f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"773edb7711364b93a2d1484a3cc98026":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a00f52831f2a4c158bdebf6f6ff88675":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2dc64b93431346c6a5a6da75129ee0fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37e1af5a7afb47d3af8f7a7104a70fce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7037ae459fe940a7b163718be878daa4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fcbde0c8c1644a7bb4fb9b5fe4b9a15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"084202134e63487a8298c8fc77abe568":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f278a7213a11466a99db7bfa1a777221","IPY_MODEL_ed9ad1e4bebb4492a0527f29acc73bc8","IPY_MODEL_513ac9794b794a2fa26ff2b22879d951"],"layout":"IPY_MODEL_e7c5257ef93543a5a4f7004139575b71"}},"f278a7213a11466a99db7bfa1a777221":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f22433901164327a72e6ffe7aec6cb7","placeholder":"​","style":"IPY_MODEL_11c4d1d06940420cb2b0bbd4e0d7c732","value":"merges.txt: 100%"}},"ed9ad1e4bebb4492a0527f29acc73bc8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c6f4318a55c41b892b774047ca377dc","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e392ef68e13747e399cfd9b0212bff1f","value":456318}},"513ac9794b794a2fa26ff2b22879d951":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ed9ecff15054c62b0b84b7c4da410ae","placeholder":"​","style":"IPY_MODEL_a8d25a5c55c64ca0be211cf84b50bae4","value":" 456k/456k [00:00&lt;00:00, 692kB/s]"}},"e7c5257ef93543a5a4f7004139575b71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f22433901164327a72e6ffe7aec6cb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11c4d1d06940420cb2b0bbd4e0d7c732":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c6f4318a55c41b892b774047ca377dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e392ef68e13747e399cfd9b0212bff1f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7ed9ecff15054c62b0b84b7c4da410ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8d25a5c55c64ca0be211cf84b50bae4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbeb81900c52455b9eb7f94c3367b55f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1bedeea988244cd69f2907c493b27737","IPY_MODEL_a55fb047a25d4ece8be6fbd7de53ceea","IPY_MODEL_0d86a09d852f4e918a342f88093bcec3"],"layout":"IPY_MODEL_bb0c3ce28a4742089fc1e1fb524d7f4d"}},"1bedeea988244cd69f2907c493b27737":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb718b8b156247ae9f196064ea3eca55","placeholder":"​","style":"IPY_MODEL_bbff59bf873c42d9b10299e6a1bd08ed","value":"special_tokens_map.json: 100%"}},"a55fb047a25d4ece8be6fbd7de53ceea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d45f612c0cd04dd39cf79c10f530575c","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a45aa360f8674e0d85d6b1d4cdb45ec2","value":150}},"0d86a09d852f4e918a342f88093bcec3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_892eb48e2b9d4d25876040aba5add90d","placeholder":"​","style":"IPY_MODEL_94e887e047ae4d61aee64056797c415f","value":" 150/150 [00:00&lt;00:00, 2.51kB/s]"}},"bb0c3ce28a4742089fc1e1fb524d7f4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb718b8b156247ae9f196064ea3eca55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbff59bf873c42d9b10299e6a1bd08ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d45f612c0cd04dd39cf79c10f530575c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a45aa360f8674e0d85d6b1d4cdb45ec2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"892eb48e2b9d4d25876040aba5add90d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94e887e047ae4d61aee64056797c415f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef520e45ad3d4030a151d5419f02529a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aaf1e16db28743d9aab4cdb5b46fb05a","IPY_MODEL_4e5d527ad82c404093e94b2c41962293","IPY_MODEL_60ba985ece214327a482bf7be8f59377"],"layout":"IPY_MODEL_a49936e35efc43c3a785d151a3c25ce9"}},"aaf1e16db28743d9aab4cdb5b46fb05a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_beb175a9063d48b69d78b4fdca1d43b9","placeholder":"​","style":"IPY_MODEL_af8ea14d79f84d628f1432117bf05daf","value":"config.json: 100%"}},"4e5d527ad82c404093e94b2c41962293":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ad2abb0a0af4ffb92940588b367b613","max":498,"min":0,"orientation":"horizontal","style":"IPY_MODEL_719fdb9518e549eb9b31e7b6f092f03c","value":498}},"60ba985ece214327a482bf7be8f59377":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_070e80aaf9cf430aac0ab2a8289420c1","placeholder":"​","style":"IPY_MODEL_6fcd09653d6840b0badec0e56ab224f3","value":" 498/498 [00:00&lt;00:00, 10.4kB/s]"}},"a49936e35efc43c3a785d151a3c25ce9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"beb175a9063d48b69d78b4fdca1d43b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af8ea14d79f84d628f1432117bf05daf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ad2abb0a0af4ffb92940588b367b613":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"719fdb9518e549eb9b31e7b6f092f03c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"070e80aaf9cf430aac0ab2a8289420c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fcd09653d6840b0badec0e56ab224f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a00476a1d67d42e985a1cfef9fd72259":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3294df96c8334e3195d80aeabd5d05f6","IPY_MODEL_b726c4d2c7234d78a90472560dd376db","IPY_MODEL_1e5f4dd711ab409091101961023e6712"],"layout":"IPY_MODEL_b4e884aea9ba4b3396ad21bf15b822ef"}},"3294df96c8334e3195d80aeabd5d05f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fb2fcab74514b87b178ad0572294c75","placeholder":"​","style":"IPY_MODEL_cfbce933dc00469493431e33f29d2be8","value":"pytorch_model.bin: 100%"}},"b726c4d2c7234d78a90472560dd376db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16e2dc4d5c274609bcafca4ee55d5d68","max":498627950,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0d980c7b8a64399833f2a276dc50496","value":498627950}},"1e5f4dd711ab409091101961023e6712":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e2e8ea0f56d4b3a8483e8a000a6fcf7","placeholder":"​","style":"IPY_MODEL_85401932b8ad4425a7652897a040b1a1","value":" 499M/499M [00:03&lt;00:00, 145MB/s]"}},"b4e884aea9ba4b3396ad21bf15b822ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fb2fcab74514b87b178ad0572294c75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfbce933dc00469493431e33f29d2be8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16e2dc4d5c274609bcafca4ee55d5d68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0d980c7b8a64399833f2a276dc50496":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e2e8ea0f56d4b3a8483e8a000a6fcf7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85401932b8ad4425a7652897a040b1a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9926041,"sourceType":"datasetVersion","datasetId":6100950}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install transformers torch tqdm nltk","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CA7oI9rhJJ0G","outputId":"f233e33e-0a27-4d7f-e2dd-1b0bc6290d90","execution":{"iopub.status.busy":"2024-11-16T17:51:12.735990Z","iopub.execute_input":"2024-11-16T17:51:12.736369Z","iopub.status.idle":"2024-11-16T17:51:24.146026Z","shell.execute_reply.started":"2024-11-16T17:51:12.736331Z","shell.execute_reply":"2024-11-16T17:51:24.144825Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport json\nimport zipfile\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom transformers import RobertaTokenizer, RobertaForMaskedLM, AdamW\nfrom tqdm import tqdm\nimport numpy as np","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y0r_tRUSJJ0I","outputId":"1c106ca5-7178-4c08-b2a5-8bf3a155bb59","execution":{"iopub.status.busy":"2024-11-16T17:51:24.148723Z","iopub.execute_input":"2024-11-16T17:51:24.149475Z","iopub.status.idle":"2024-11-16T17:51:24.154766Z","shell.execute_reply.started":"2024-11-16T17:51:24.149436Z","shell.execute_reply":"2024-11-16T17:51:24.153778Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class SolidityDataset(Dataset):\n    def __init__(self, folder_path, tokenizer, max_length=256):\n        self.folder_path = folder_path\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.samples = []\n\n        print(f\"Reading files from folder: {folder_path}\")\n\n        # Iterate through all .txt files in the directory\n        file_count = 0\n        valid_count = 0\n        \n        for root, _, files in os.walk(folder_path):\n            for file_name in files:\n                if file_name.endswith('.txt'):  # Only process .txt files\n                    file_count += 1\n                    file_path = os.path.join(root, file_name)\n                    try:\n                        # Load the JSON data from the file\n                        with open(file_path, 'r') as file:\n                            data = json.load(file)\n                            code = data.get(\"Code\")\n                            if code:\n                                self.samples.append(code)\n                                valid_count += 1\n                            else:\n                                print(f\"Warning: 'Code' field not found in {file_name}\")\n                    except json.JSONDecodeError:\n                        print(f\"Error decoding JSON in file: {file_name}\")\n                    except Exception as e:\n                        print(f\"Unexpected error with file {file_name}: {e}\")\n\n        print(f\"Processed {file_count} files. Loaded {valid_count} valid samples.\")\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        code = self.samples[idx]\n        encoded_input = self.tokenizer(\n            code,\n            max_length=self.max_length,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\"\n        )\n        return encoded_input['input_ids'].squeeze(), encoded_input['attention_mask'].squeeze()\n\n\n# Initialize dataset with logging\nfolder_path = \"/kaggle/input/solidity-code\"\n\ndataset = SolidityDataset(folder_path=solidity_code_path, tokenizer=tokenizer)\n\n# Check if the dataset contains any samples\nif len(dataset) == 0:\n    raise ValueError(f\"No samples found in folder: {folder_path}. Please check your data.\")\n\n# Split dataset\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nprint(f\"Dataset split into {len(train_dataset)} training samples and {len(val_dataset)} validation samples.\")","metadata":{"id":"ZIH5tSa8JJ0I","execution":{"iopub.status.busy":"2024-11-16T18:20:59.489696Z","iopub.execute_input":"2024-11-16T18:20:59.490552Z","iopub.status.idle":"2024-11-16T18:21:15.184589Z","shell.execute_reply.started":"2024-11-16T18:20:59.490508Z","shell.execute_reply":"2024-11-16T18:21:15.183674Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Reading files from folder: /kaggle/input/solidity-code\nWarning: 'Code' field not found in getImpl.txt\nWarning: 'Code' field not found in onFlashAction.txt\nWarning: 'Code' field not found in getState.txt\nWarning: 'Code' field not found in constructor.txt\nWarning: 'Code' field not found in tokenTransferFrom.txt\nWarning: 'Code' field not found in computeId.txt\nWarning: 'Code' field not found in getState.txt\nWarning: 'Code' field not found in liquidity.txt\nWarning: 'Code' field not found in getUniswapV3PoolFromId.txt\nWarning: 'Code' field not found in getPoolId.txt\nWarning: 'Code' field not found in getAccountFeesBase.txt\nWarning: 'Code' field not found in _onBeforeDeposit.txt\nWarning: 'Code' field not found in _installPlugin.txt\nWarning: 'Code' field not found in _revertBytes.txt\nWarning: 'Code' field not found in get_deposit_root.txt\nWarning: 'Code' field not found in get_deposit_count.txt\nWarning: 'Code' field not found in deposit.txt\nProcessed 21298 files. Loaded 21281 valid samples.\nDataset split into 17024 training samples and 4257 validation samples.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load pre-trained CodeBERT\ntokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\nmodel = RobertaForMaskedLM.from_pretrained(\"microsoft/codebert-base\")\n\n# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9062970c8e7b48cabaf29e0b158848c0","7cc3f42ec30f4116a7c87ca563373b38","320ef60e7c4d48da903db5949d44939e","e725951ac26d4de3996cace41fc82090","d335bb6f90dc415e872cfadf06b505cc","f2b19aa14ef847e49167b775cd1dc0b9","ddc251aa852b42fe86d3acba0779e746","688bda0b9635459099fa4396bf68c50f","8848928c425c43aeb7319501e9b65b3a","49a8f66e4fc646ee84683656cf39a236","04eb1425b6494762841c14fbe4345682","d0dcd7a0c2ce46a19833029b9cd68bf5","310de2b8921a477b992f1f3ef8455eb1","e8c492d6806e4862b02f00ad8b0af61c","318da11eabf24278bcda696246972b0a","68ace88f8cb544e79f19d7582a7f55f5","773edb7711364b93a2d1484a3cc98026","a00f52831f2a4c158bdebf6f6ff88675","2dc64b93431346c6a5a6da75129ee0fe","37e1af5a7afb47d3af8f7a7104a70fce","7037ae459fe940a7b163718be878daa4","4fcbde0c8c1644a7bb4fb9b5fe4b9a15","084202134e63487a8298c8fc77abe568","f278a7213a11466a99db7bfa1a777221","ed9ad1e4bebb4492a0527f29acc73bc8","513ac9794b794a2fa26ff2b22879d951","e7c5257ef93543a5a4f7004139575b71","8f22433901164327a72e6ffe7aec6cb7","11c4d1d06940420cb2b0bbd4e0d7c732","7c6f4318a55c41b892b774047ca377dc","e392ef68e13747e399cfd9b0212bff1f","7ed9ecff15054c62b0b84b7c4da410ae","a8d25a5c55c64ca0be211cf84b50bae4","fbeb81900c52455b9eb7f94c3367b55f","1bedeea988244cd69f2907c493b27737","a55fb047a25d4ece8be6fbd7de53ceea","0d86a09d852f4e918a342f88093bcec3","bb0c3ce28a4742089fc1e1fb524d7f4d","fb718b8b156247ae9f196064ea3eca55","bbff59bf873c42d9b10299e6a1bd08ed","d45f612c0cd04dd39cf79c10f530575c","a45aa360f8674e0d85d6b1d4cdb45ec2","892eb48e2b9d4d25876040aba5add90d","94e887e047ae4d61aee64056797c415f","ef520e45ad3d4030a151d5419f02529a","aaf1e16db28743d9aab4cdb5b46fb05a","4e5d527ad82c404093e94b2c41962293","60ba985ece214327a482bf7be8f59377","a49936e35efc43c3a785d151a3c25ce9","beb175a9063d48b69d78b4fdca1d43b9","af8ea14d79f84d628f1432117bf05daf","3ad2abb0a0af4ffb92940588b367b613","719fdb9518e549eb9b31e7b6f092f03c","070e80aaf9cf430aac0ab2a8289420c1","6fcd09653d6840b0badec0e56ab224f3","a00476a1d67d42e985a1cfef9fd72259","3294df96c8334e3195d80aeabd5d05f6","b726c4d2c7234d78a90472560dd376db","1e5f4dd711ab409091101961023e6712","b4e884aea9ba4b3396ad21bf15b822ef","7fb2fcab74514b87b178ad0572294c75","cfbce933dc00469493431e33f29d2be8","16e2dc4d5c274609bcafca4ee55d5d68","b0d980c7b8a64399833f2a276dc50496","2e2e8ea0f56d4b3a8483e8a000a6fcf7","85401932b8ad4425a7652897a040b1a1"]},"id":"MB9Bpq_2JJ0J","outputId":"8fb6d314-3b3f-4d65-bd15-a25982116cb6","execution":{"iopub.status.busy":"2024-11-16T18:21:15.186670Z","iopub.execute_input":"2024-11-16T18:21:15.187095Z","iopub.status.idle":"2024-11-16T18:21:16.379836Z","shell.execute_reply.started":"2024-11-16T18:21:15.187049Z","shell.execute_reply":"2024-11-16T18:21:16.378812Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"RobertaForMaskedLM(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (lm_head): RobertaLMHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Define Early Stopping\nclass EarlyStopping:\n    def __init__(self, patience=3, mode=\"max\"):\n        self.patience = patience\n        self.mode = mode\n        self.best_score = None\n        self.counter = 0\n        self.should_stop = False\n\n    def __call__(self, current_score):\n        if self.best_score is None or (\n            (self.mode == \"max\" and current_score > self.best_score) or\n            (self.mode == \"min\" and current_score < self.best_score)\n        ):\n            self.best_score = current_score\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.should_stop = True\n\n# Define fine-tuning function\ndef fine_tune_model(model, train_loader, val_loader, tokenizer, epochs=10, learning_rate=1e-5):\n    optimizer = AdamW(model.parameters(), lr=learning_rate)\n    early_stopping = EarlyStopping(patience=3, mode=\"max\")\n    \n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        correct_predictions = 0\n        total_masked_tokens = 0\n\n        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\") as pbar:\n            for input_ids, attention_mask in train_loader:\n                input_ids = input_ids.to(device)\n                attention_mask = attention_mask.to(device)\n\n                # Mask tokens\n                labels = input_ids.clone()\n                probability_matrix = torch.full(labels.shape, 0.25)  # Increased masking probability to 25%\n                masked_indices = torch.bernoulli(probability_matrix).bool()\n                labels[~masked_indices] = -100\n\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n                loss = outputs.loss\n                logits = outputs.logits\n\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n                total_loss += loss.item()\n\n                predictions = torch.argmax(logits, dim=-1)\n                mask_token_indices = (labels != -100)\n                correct_predictions += (predictions[mask_token_indices] == labels[mask_token_indices]).sum().item()\n                total_masked_tokens += mask_token_indices.sum().item()\n\n                pbar.set_postfix(loss=total_loss / (pbar.n + 1), accuracy=correct_predictions / total_masked_tokens)\n                pbar.update(1)\n\n        # Validation step\n        model.eval()\n        val_loss = 0\n        val_correct = 0\n        val_total_masked = 0\n\n        with torch.no_grad():\n            for input_ids, attention_mask in val_loader:\n                input_ids = input_ids.to(device)\n                attention_mask = attention_mask.to(device)\n\n                labels = input_ids.clone()\n                probability_matrix = torch.full(labels.shape, 0.25)\n                masked_indices = torch.bernoulli(probability_matrix).bool()\n                labels[~masked_indices] = -100\n\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n                logits = outputs.logits\n\n                val_loss += outputs.loss.item()\n                predictions = torch.argmax(logits, dim=-1)\n                mask_token_indices = (labels != -100)\n                val_correct += (predictions[mask_token_indices] == labels[mask_token_indices]).sum().item()\n                val_total_masked += mask_token_indices.sum().item()\n\n        val_accuracy = val_correct / val_total_masked\n        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {total_loss/len(train_loader):.4f} | \"\n              f\"Val Loss: {val_loss/len(val_loader):.4f} | Val Accuracy: {val_accuracy:.4f}\")\n\n        early_stopping(val_accuracy)\n        if early_stopping.should_stop:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n            \n# Fine-tune the model\nfine_tune_model(model, train_loader, val_loader, tokenizer)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CvUfYFiJJ0K","outputId":"93e3628d-4a8e-4667-c294-b328e70aefe4","execution":{"iopub.status.busy":"2024-11-16T18:21:45.533025Z","iopub.execute_input":"2024-11-16T18:21:45.533411Z","iopub.status.idle":"2024-11-16T19:24:02.999806Z","shell.execute_reply.started":"2024-11-16T18:21:45.533373Z","shell.execute_reply":"2024-11-16T19:24:02.998433Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nEpoch 1/10: 100%|██████████| 2128/2128 [17:36<00:00,  2.01it/s, accuracy=0.92, loss=0.651] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 - Train Loss: 0.6511 | Val Loss: 0.0235 | Val Accuracy: 0.9943\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 2128/2128 [17:32<00:00,  2.02it/s, accuracy=0.993, loss=0.0239]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10 - Train Loss: 0.0239 | Val Loss: 0.0084 | Val Accuracy: 0.9955\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|██████████| 2128/2128 [17:32<00:00,  2.02it/s, accuracy=0.995, loss=0.01]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10 - Train Loss: 0.0100 | Val Loss: 0.0063 | Val Accuracy: 0.9960\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10:  31%|███       | 662/2128 [05:27<12:05,  2.02it/s, accuracy=0.996, loss=0.0077] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 100\u001b[0m\n\u001b[1;32m     97\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Fine-tune the model\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m \u001b[43mfine_tune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[26], line 50\u001b[0m, in \u001b[0;36mfine_tune_model\u001b[0;34m(model, train_loader, val_loader, tokenizer, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     49\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 50\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     54\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:647\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;66;03m# In-place operations to update the averages at the same time\u001b[39;00m\n\u001b[1;32m    646\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta1))\n\u001b[0;32m--> 647\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m denom \u001b[38;5;241m=\u001b[39m exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m.\u001b[39madd_(group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    650\u001b[0m step_size \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Save the fine-tuned model\nsave_dir = \"/kaggle/working/finetuned_model/\"\nos.makedirs(save_dir, exist_ok=True)\nmodel.save_pretrained(save_dir)\ntokenizer.save_pretrained(save_dir)\n\nprint(f\"Model saved to {save_dir}\")","metadata":{"id":"TfzO-a_HJJ0L","execution":{"iopub.status.busy":"2024-11-16T19:24:06.767957Z","iopub.execute_input":"2024-11-16T19:24:06.768846Z","iopub.status.idle":"2024-11-16T19:24:08.071542Z","shell.execute_reply.started":"2024-11-16T19:24:06.768802Z","shell.execute_reply":"2024-11-16T19:24:08.070585Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Model saved to /kaggle/working/finetuned_model/\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test load\n\nfrom transformers import RobertaTokenizer, RobertaForMaskedLM\n\nsave_dir = \"/kaggle/working/finetuned_model/\"\n\n# Load the tokenizer and model\ntokenizer = RobertaTokenizer.from_pretrained(save_dir)\nmodel = RobertaForMaskedLM.from_pretrained(save_dir)\n\n# Move to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nprint(\"Model and tokenizer loaded successfully!\")\n\ndef get_embeddings(model, code_snippet):\n    model.eval()\n    with torch.no_grad():\n        encoded_input = tokenizer(\n            code_snippet,\n            max_length=256,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\"\n        )\n        input_ids = encoded_input['input_ids'].to(device)\n        attention_mask = encoded_input['attention_mask'].to(device)\n\n        # Get the last hidden state as embeddings\n        outputs = model.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        embeddings = outputs.last_hidden_state[:, 0, :]  # Use CLS token embedding\n        return embeddings.cpu().numpy()\n\n# Example usage:\ncode_snippet = \"function add(uint256 a, uint256 b) public pure returns (uint256) { return a + b; }\"\nembedding = get_embeddings(model, code_snippet)\nprint(embedding)\n","metadata":{"id":"JIJYTVwoJJ0L","execution":{"iopub.status.busy":"2024-11-16T19:24:14.208164Z","iopub.execute_input":"2024-11-16T19:24:14.208863Z","iopub.status.idle":"2024-11-16T19:24:14.959527Z","shell.execute_reply.started":"2024-11-16T19:24:14.208821Z","shell.execute_reply":"2024-11-16T19:24:14.958496Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Model and tokenizer loaded successfully!\n[[ 4.05681223e-01 -3.65111262e-01 -9.25921023e-01  1.15476130e-02\n   2.88898349e-01  2.14949012e-01  3.53764266e-01 -1.15859821e-01\n  -2.95966744e-01 -5.41716993e-01  6.43636763e-01 -1.64671063e-01\n  -4.27890003e-01 -2.05586225e-01  6.39046609e-01 -1.27622500e-01\n  -7.40435898e-01 -5.17755091e-01  3.94157648e-01 -2.48501658e-01\n  -8.95656109e-01  1.52037680e-01 -1.10072277e-01  7.81248808e-01\n   5.62808871e-01 -9.96119320e-01  9.59416091e-01  1.03596938e+00\n  -9.69998166e-02  3.71292442e-01  9.31655288e-01 -1.32916045e+00\n  -4.18929189e-01 -8.03332180e-02 -2.88462728e-01  7.02840328e-01\n   4.26392823e-01  4.13250476e-01  2.30653286e-01  8.30822825e-01\n  -7.70308256e-01 -8.91805589e-02  2.42958814e-01 -2.20116958e-01\n  -4.35930014e-01  1.24288857e-01 -7.07863644e-02 -1.17232827e-02\n   3.90237004e-01 -4.76665109e-01  3.01774204e-01 -6.53944671e-01\n   1.74259290e-01  4.23410684e-01  6.19129241e-01 -1.59401804e-01\n  -1.23386487e-01  7.30553448e-01  1.17239773e+00 -2.84547001e-01\n   5.00638366e-01  5.16337097e-01 -4.64436740e-01 -3.76762718e-01\n  -3.06858756e-02 -1.41207695e+00 -3.61820728e-01  5.54638743e-01\n   4.83367950e-01  8.81909251e-01  2.88576961e-01  7.05658942e-02\n   1.21699788e-01  2.92317033e-01 -2.54532814e-01 -1.61745161e-01\n   1.15488380e-01  1.42396522e+00 -3.07961762e-01 -8.49332571e-01\n   1.57966495e-01  3.00616883e-02  1.56183496e-01 -1.85192838e-01\n  -2.44786352e-01 -8.31633985e-01 -4.10271794e-01 -3.27236027e-01\n   3.71627778e-01 -5.72556496e-01  6.53773606e-01 -1.55742958e-01\n   5.50908148e-02 -4.99993920e-01  9.63604927e-01  1.05314022e-02\n  -2.86907613e-01 -7.06601620e-01  2.19435528e-01 -8.55080307e-01\n   2.67039269e-01 -2.33210146e-01  3.53010767e-03 -1.70779121e+00\n  -1.54961646e-02  1.23116374e+00  5.19203469e-02  1.35982111e-01\n  -3.44699770e-01 -7.90338576e-01 -1.12737991e-01 -4.40846562e-01\n  -6.67689264e-01  3.01387571e-02 -8.41386437e-01  1.06163621e+00\n  -2.70993441e-01  9.19752538e-01  2.86645114e-01  1.30459332e+00\n  -8.84379923e-01 -5.77646613e-01 -2.58261979e-01 -1.93874598e-01\n   3.04524064e-01  6.52910590e-01 -2.04532504e-01  1.50268525e-01\n   1.38091838e+00  4.71485294e-02 -1.15676832e+00  2.32289210e-01\n  -7.30308712e-01  4.98815238e-01 -7.23923370e-02  8.36049199e-01\n  -6.82905495e-01  8.72580469e-01  1.04201889e+00 -8.56648564e-01\n  -4.52501714e-01  7.08984137e-01  2.25312918e-01  1.37257636e-01\n   8.95350277e-01 -4.06250834e-01 -8.42020512e-01 -5.67893863e-01\n   2.50282824e-01  1.46095842e-01 -2.88102984e-01  6.80644810e-01\n  -1.79233670e-01 -1.96353391e-01 -7.70120144e-01 -3.85830492e-01\n   8.93331170e-01 -1.27932048e+00 -5.16664147e-01 -6.79032147e-01\n  -3.61401230e-01  7.44417548e-01  3.22123975e-01 -4.40213382e-01\n   1.75490290e-01  1.88776627e-01  3.52233142e-01 -6.17404997e-01\n   2.94637829e-01  3.58147591e-01 -6.99356139e-01  6.73049092e-01\n  -3.47628176e-01  2.82232553e-01 -4.06059384e-01 -1.34122610e+00\n  -2.54963309e-01 -6.37990162e-02  3.37066948e-01  9.48402047e-01\n  -2.55017519e-01  4.79836255e-01 -2.95428276e-01 -8.03849995e-02\n   1.51772296e+00 -8.33188355e-01 -2.27038682e-01 -6.31297410e-01\n   1.20809630e-01  4.63702053e-01 -5.11739366e-02  1.11421633e+00\n   2.03191146e-01  6.52422905e-02  1.17115331e+00 -2.73809642e-01\n   1.88865393e-01  1.26345262e-01  9.72011030e-01 -4.16547433e-02\n   3.88148010e-01  8.78851354e-01  1.22194268e-01 -8.22942376e-01\n   4.21540625e-02  7.70065606e-01 -2.29275241e-01  1.40387818e-01\n   3.84926558e-01 -2.05587164e-01  7.81379044e-01  3.32753986e-01\n   1.08746111e+00  5.52696228e-01 -6.42539799e-01 -1.85269788e-01\n   4.61365789e-01  7.84474730e-01  4.65833098e-01  3.58680040e-02\n   2.00187340e-01  6.75443769e-01 -1.60872683e-01  3.23814958e-01\n  -4.63128835e-01  1.03558183e+00  3.72537464e-01  7.28191853e-01\n  -3.78949255e-01 -1.15229023e+00  2.20475405e-01 -2.43678734e-01\n   5.14889173e-02  6.22571290e-01  9.53465551e-02 -1.23987436e+00\n   3.95470768e-01 -1.53132081e+00 -2.95591980e-01  7.12038755e-01\n   3.28212708e-01 -1.12493777e+00  5.04286923e-02  3.31384316e-02\n   5.56829035e-01  4.66519564e-01 -4.80767600e-02 -5.94682276e-01\n  -4.91758138e-01  2.87616789e-01 -5.94011068e-01 -4.78508733e-02\n  -4.91835058e-01 -3.48684907e-01 -4.72210348e-01  8.90552923e-02\n   1.27485916e-01  1.21501073e-01  5.40891886e-01 -4.70321834e-01\n  -1.12868607e+00  3.91968489e-01  4.72446442e-01 -1.98547259e-01\n  -3.35359365e-01 -6.44756973e-01  9.02742730e-04  6.20389581e-01\n  -9.63449478e-02  2.59332895e-01 -1.02565575e+00  5.25621831e-01\n  -1.04141116e-01 -6.42289221e-01  2.18103334e-01 -5.90403378e-01\n   8.76224399e-01 -1.00156820e+00 -4.68909651e-01 -3.83212090e-01\n  -2.46952504e-01  1.00622654e+00 -8.44341703e-03 -2.86091894e-01\n   7.16578782e-01  1.05645108e+00 -1.86932385e-01 -1.11395717e+00\n   6.25135228e-02  1.06062019e+00 -5.71362190e-02 -1.66663051e-01\n  -5.60443461e-01 -6.70080960e-01 -2.92457640e-01 -6.85428381e-02\n   6.56787932e-01  1.21336348e-01  3.37762773e-01  1.83484867e-01\n  -1.12074792e+00 -5.14090061e-03 -3.59044552e-01 -3.50134075e-01\n   1.06955516e+00 -1.25541657e-01 -4.42324281e-01 -1.58377099e+00\n   3.06158543e-01  2.75298357e-01  1.17649090e+00 -1.13088906e+00\n   3.47116560e-01  5.68200350e-01 -1.58046663e-01  8.93509209e-01\n   4.28439200e-01 -1.32659897e-01  6.67395115e-01 -1.02158582e+00\n  -7.46418089e-02  5.26416004e-01  8.62041831e-01  4.02547233e-03\n  -2.62444556e-01  5.32365978e-01 -7.50253201e-01  2.29361773e-01\n  -2.30489075e-01  1.36900377e+00  4.72389460e-01  1.17325805e-01\n  -6.45592451e-01  8.96337092e-01  7.66789556e-01  5.52100956e-01\n  -2.94728696e-01  1.61968376e-02 -2.41371281e-02  1.40812516e-01\n   4.69388217e-01 -5.98005295e-01 -1.17510688e+00  4.26670104e-01\n   9.96933520e-01  1.25100625e+00 -8.78899932e-01 -4.30729389e-01\n   1.83778666e-02 -1.93939537e-01  7.34089464e-02  1.57799482e-01\n   1.32489502e-01 -4.56873626e-01  4.84650470e-02  2.40710783e+00\n   1.07326651e+00 -4.53715831e-01 -4.51261729e-01  2.00146839e-01\n  -9.99046743e-01  4.23883468e-01 -7.26140618e-01 -6.85462236e-01\n   4.24139619e-01 -2.20934227e-01 -8.16412270e-01 -4.71453905e-01\n   1.10499537e+00  3.79769295e-01  4.32383269e-01  1.09997295e-01\n  -2.32867047e-01 -4.88008708e-01  4.81164902e-01  1.56218233e-02\n  -4.10970971e-02 -5.05630255e-01 -1.74844670e+00 -6.85806453e-01\n  -7.72250667e-02 -6.99989915e-01 -2.60600280e-02 -1.89285591e-01\n  -5.20447433e-01 -6.75700665e-01  1.13971794e+00  4.08699989e-01\n   6.68749690e-01  2.30162203e-01 -7.20305681e-01 -1.58163261e+00\n   6.19184412e-02  1.22399235e+00  7.09342072e-03 -7.92083025e-01\n   8.22884142e-02 -4.00352448e-01  2.65483797e-01  5.06857261e-02\n  -5.85236073e-01 -6.97604001e-01 -4.79836971e-01 -1.62019789e-01\n   1.84841380e-01  4.91087019e-01 -1.47928655e-01  8.60179141e-02\n   6.37353420e-01 -6.46957994e-01  8.54403019e-01 -1.44215599e-01\n   4.59363371e-01 -7.57041156e-01  2.33780399e-01 -1.57246277e-01\n   9.93651226e-02  9.01629567e-01 -9.03934240e-01  5.39982498e-01\n   2.83536259e-02 -2.83094049e-01  4.45200838e-02  2.60707021e-01\n  -2.12674856e-01 -3.76782939e-02 -3.82876068e-01 -9.16887522e-01\n   3.72310042e-01 -1.71773985e-01  4.05247688e-01  8.64109576e-01\n  -2.50617921e-01  1.46709096e+00  3.60398978e-01  1.16773047e-01\n   6.62306011e-01  6.91447556e-01 -1.25545591e-01 -4.79700714e-01\n   3.53377402e-01 -2.73464501e-01 -1.65398866e-01  1.56203628e-01\n  -9.12550211e-01  1.43605268e+00  7.08116710e-01  7.37857878e-01\n  -1.29455912e+00  1.29532433e+00  1.47389674e+00 -7.88299963e-02\n   3.62511069e-01 -8.82904768e-01  8.30334723e-01  2.19773695e-01\n  -3.74560118e-01  5.14485873e-02 -9.46766794e-01  5.95416963e-01\n   5.05389869e-01 -4.59744275e-01  4.70533744e-02 -6.80195630e-01\n  -1.02963403e-03 -7.12957859e-01 -3.51668507e-01  5.55755794e-01\n  -5.27671464e-02 -5.47980964e-01 -2.15086609e-01  1.48120254e-01\n   6.67169914e-02 -5.49523056e-01 -3.63445878e-01 -5.36046326e-01\n  -1.52707279e-01 -6.19583607e-01  4.24387991e-01 -3.14880461e-02\n  -1.55624017e-01 -5.71954668e-01  8.88302699e-02  3.65246445e-01\n   4.71837297e-02 -7.13825047e-01  1.27973363e-01  4.99443382e-01\n  -3.74343038e-01 -5.12287855e-01  5.83220184e-01  1.13264676e-02\n   3.93127084e-01 -3.84630322e-01 -5.58405697e-01  9.92702425e-01\n  -4.40123439e-01  1.32440686e+00  5.06487675e-02 -4.23555169e-03\n   1.64777905e-01  9.45921719e-01  7.30674744e-01  3.09345603e-01\n   7.76418149e-02  6.90945923e-01 -9.93515104e-02  6.20978892e-01\n   7.66002357e-01  5.84918559e-02 -5.20932615e-01  6.47481859e-01\n   5.39616287e-01  4.23420340e-01 -5.06853640e-01 -1.80351347e-01\n   5.21939814e-01 -7.56994188e-01  3.41325760e-01  5.04270196e-01\n  -6.18855059e-01 -2.38843411e-02  2.26199806e-01  6.61873221e-01\n  -3.09484061e-02  2.64430761e-01  8.57637763e-01  5.15717745e-01\n   1.04696381e+00 -9.76718664e-01 -1.77387670e-01  4.94185477e-01\n  -2.47869313e-01 -4.67169613e-01  7.30045438e-01  4.73187208e-01\n   1.74875200e+00 -1.52273402e-01  1.38911501e-01  2.51054801e-02\n   7.08914399e-01 -5.59252679e-01  6.85124040e-01 -5.79700321e-02\n   1.09304321e+00  6.63027093e-02  5.22143781e-01 -8.22535217e-01\n  -2.89233357e-01  5.05875409e-01  4.66697663e-01 -1.56862366e+00\n   5.72041199e-02  1.00403023e+00 -2.25991204e-01 -6.75986826e-01\n   3.38579774e-01  2.36433536e-01 -1.41517147e-01 -5.00037223e-02\n  -8.57034996e-02 -3.00093740e-01  7.31563926e-01 -6.77056432e-01\n  -7.70326734e-01  1.01928437e+00  2.77039558e-01  9.44844007e-01\n   6.58935487e-01  8.35602701e-01 -9.99675214e-01  6.46318793e-01\n   2.89928645e-01  7.94834375e-01 -8.45649660e-01  3.58251154e-01\n   1.41338456e+00  2.85757631e-01  9.64573979e-01  1.27729905e+00\n  -2.47476503e-01  4.14888293e-01 -1.31092751e+00 -1.57253623e-01\n  -5.34223616e-02  1.14586605e-02 -5.03597975e-01  1.82671864e-02\n   1.71888428e+01  7.62160063e-01 -3.61508578e-01  1.38245797e+00\n   3.37259889e-01  2.02941909e-01 -1.44531524e+00  8.18364799e-01\n  -6.03423536e-01  5.78625321e-01 -2.18633235e-01 -4.39653456e-01\n   4.25479189e-03  7.95592010e-01 -2.16296598e-01  3.30526501e-01\n  -4.97036427e-03  2.48973861e-01 -1.63435668e-01 -7.28150085e-02\n  -1.11818564e+00  1.82890192e-01  2.01241881e-01 -1.64382815e-01\n  -5.00823796e-01 -8.99290200e-03  1.08161914e+00  5.77227533e-01\n   7.00276017e-01 -8.96722496e-01  1.62292123e+00  3.70929539e-01\n   6.00822531e-02  8.19423199e-02 -1.57234177e-01 -1.38472688e+00\n  -7.42725551e-01  3.18011791e-02  5.24365604e-01 -1.07695317e+00\n   7.03572750e-01 -1.11685053e-01  2.74823844e-01  1.70681453e+00\n   8.88996363e-01 -2.75346842e-02 -2.09656820e-01  1.28630292e+00\n  -5.91605544e-01  2.97481149e-01  1.04790069e-02 -9.26464558e-01\n  -5.86533070e-01  2.20173821e-01 -6.50757015e-01  2.47887477e-01\n  -2.08009273e-01  1.16915262e+00 -6.69787169e-01  6.96510136e-01\n  -6.03748977e-01  8.57224390e-02 -6.84616029e-01 -3.18687528e-01\n   3.23302358e-01  5.66385090e-01  4.97976482e-01 -5.43906987e-01\n   1.72105283e-01 -3.11171532e-01  1.12674451e+00  9.16383684e-01\n  -9.30541337e-01 -3.16019982e-01 -5.95836997e-01 -6.74724102e-01\n  -7.09497854e-02  4.40234423e-01 -1.30877888e+00 -1.03736198e+00\n   7.58921146e-01 -5.61522394e-02  1.41085029e-01 -3.56837183e-01\n   7.18704760e-01 -4.52607065e-01 -5.21883965e-01  4.70978886e-01\n   5.97457111e-01  8.79558265e-01  9.40308645e-02 -1.52374834e-01\n  -4.81963068e-01 -5.53655446e-01  3.16608995e-02 -1.17466234e-01\n  -5.10727346e-01  1.28646940e-01  1.61908850e-01 -4.01831150e-01\n  -3.16235125e-01 -8.83222446e-02  7.51897343e-04  1.18461025e+00\n  -1.22050360e-01  3.50091815e-01 -1.13971554e-01  6.86369240e-02\n  -1.94412142e-01  7.58470967e-02 -1.03060162e+00  6.68094456e-01\n   1.45401788e+00 -9.70835865e-01  4.24894467e-02  4.82804269e-01\n  -8.15701857e-02 -4.14703101e-01  6.94149554e-01 -2.25278437e-01\n   6.91585660e-01  4.96282339e-01  1.51684093e+00 -8.31114054e-01\n  -6.18930936e-01  5.17108262e-01  3.13856691e-01  1.23565912e+00\n   6.86979830e-01  8.54231715e-02  5.63028574e-01 -6.92738742e-02\n  -1.96330816e-01  5.02981484e-01  2.38168702e-01  3.55582803e-01\n  -1.41981333e-01 -5.50409138e-01 -6.71021193e-02  1.38085991e-01\n   4.48255062e-01  1.22094750e-01  6.27777755e-01 -8.82906556e-01\n   1.09407270e+00 -7.68147111e-01 -6.47950113e-01  8.12923014e-02\n   7.55394548e-02  2.58472532e-01  5.85148893e-02 -7.25503743e-01\n   3.23678315e-01  4.00298228e-03  2.45434687e-01 -5.31095266e-02\n  -5.53374112e-01  7.09665298e-01  1.02421433e-01  1.29697576e-01\n  -1.92360088e-01 -1.52923095e+00  5.23163497e-01 -7.08750606e-01\n  -6.52725577e-01 -4.89019394e-01 -1.81644604e-01  4.45140898e-01\n   1.91344276e-01 -1.22102225e+00  5.60412288e-01 -3.75667870e-01\n   1.14020005e-01  6.89591944e-01 -4.99497801e-01  3.74125719e-01\n   6.10670328e-01 -8.85387287e-02 -5.64619780e-01 -1.59564644e-01]]\n","output_type":"stream"}]}]}